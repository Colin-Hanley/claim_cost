{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T18:36:58.257690Z",
     "start_time": "2024-06-12T18:36:56.682328Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "claims_data = pd.read_excel(\"claims_data.xlsx\")"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T18:36:58.262022Z",
     "start_time": "2024-06-12T18:36:58.258689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "claims_data.loc[claims_data[\"Notification_period\"] < 0, \"Notification_period\"] = np.nan\n",
    "claims_data.loc[claims_data[\"PH_considered_TP_at_fault\"] == \"#\", \"PH_considered_TP_at_fault\"] = np.nan"
   ],
   "id": "2eb1972bed8b5e2e",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T18:36:58.267140Z",
     "start_time": "2024-06-12T18:36:58.262022Z"
    }
   },
   "cell_type": "code",
   "source": "claims_data.drop(columns=[\"Claim Number\", \"date_of_loss\", \"Loss_code\", \"Loss_description\", \"Capped Incurred\"], inplace=True)",
   "id": "d6d63a91b7f56b28",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T18:36:58.273491Z",
     "start_time": "2024-06-12T18:36:58.268155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for col in claims_data.select_dtypes(include=[\"object\"]).columns:\n",
    "    claims_data[col] = claims_data[col].astype(\"category\")\n",
    "   "
   ],
   "id": "6e7b7699f9b7ab40",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T18:36:58.288568Z",
     "start_time": "2024-06-12T18:36:58.273491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot_encode_categorical_columns(df: pd.DataFrame) -> (pd.DataFrame, OneHotEncoder):\n",
    "    \"\"\"\n",
    "    One-hot encodes all categorical columns in the DataFrame using OneHotEncoder.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing columns to be encoded.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with categorical columns one-hot encoded.\n",
    "    \"\"\"\n",
    "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "    encoded_df = pd.DataFrame(ohe.fit_transform(df[categorical_columns]))\n",
    "    \n",
    "\n",
    "    encoded_df.columns = ohe.get_feature_names_out(categorical_columns)\n",
    "    df = df.drop(columns=categorical_columns).reset_index(drop=True)\n",
    "    encoded_df = encoded_df.reset_index(drop=True)\n",
    "    \n",
    "    return pd.concat([df, encoded_df], axis=1), ohe\n",
    "\n",
    "encoded_claims, encoder = one_hot_encode_categorical_columns(claims_data)"
   ],
   "id": "ace2bf4967f4c7c3",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T18:36:58.295777Z",
     "start_time": "2024-06-12T18:36:58.288568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, temp = train_test_split(claims_data, test_size=0.25, random_state=32, shuffle=True)\n",
    "val, test = train_test_split(temp, test_size=0.4, random_state=32, shuffle=True)\n",
    "\n",
    "# Display the results\n",
    "print(\"Training data size:\", len(train) / (len(train) + len(val) + len(test)) )\n",
    "print(\"Validation data size:\", len(val) / (len(train) + len(val) + len(test)))\n",
    "print(\"Testing data size:\", len(test)/ (len(train) + len(val) + len(test)))"
   ],
   "id": "67783be8bea27b03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 0.7499674944740606\n",
      "Validation data size: 0.14991548563255752\n",
      "Testing data size: 0.10011701989338187\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T18:36:58.317629Z",
     "start_time": "2024-06-12T18:36:58.295777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import namedtuple\n",
    "DataSet = namedtuple('DataSet', ['features', 'target'])\n",
    "train_set = DataSet(features=train.drop(columns=\"Incurred\"), target=train[\"Incurred\"])\n",
    "val_set = DataSet(features=val.drop(columns=\"Incurred\"), target=val[\"Incurred\"])\n",
    "test_set = DataSet(features=test.drop(columns =\"Incurred\") , target=test[\"Incurred\"])\n",
    "train_d_matrix = xgb.DMatrix(train_set.features, label=train_set.target, enable_categorical=True)\n",
    "val_d_matrix = xgb.DMatrix(val_set.features, label=val_set.target, enable_categorical=True)\n",
    "test_d_matrix = xgb.DMatrix(test_set.features, label=test_set.target, enable_categorical=True)"
   ],
   "id": "688a19c0a71f83e6",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T18:37:58.594500Z",
     "start_time": "2024-06-12T18:36:58.317629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from random import randint, uniform\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from flaml import AutoML\n",
    "\n",
    "automl = AutoML()\n",
    "\n",
    "automl_settings = {\n",
    "    \"time_budget\": 60, \n",
    "    \"metric\": 'mae', \n",
    "    \"task\": 'regression', \n",
    "    \"n_splits\": 5, \n",
    "    \"sample\": True, \n",
    "    \"estimator_list\": ['xgboost'],  \n",
    "    \"log_file_name\": 'flaml.log', \n",
    "    \"eval_method\": \"cv\", \n",
    "    \"max_iter\": 200, \n",
    "    \"early_stop\": True,  \n",
    "    \"n_jobs\": 4,\n",
    "    \"ensemble\": True,\n",
    "    \"custom_hp\": {\n",
    "        'xgboost': {\n",
    "            'max_depth': {'domain': randint(3, 10), 'init_value': 6},\n",
    "            'subsample': {'domain': uniform(0.6, 1.0), 'init_value': 0.8},\n",
    "            'learning_rate': {'domain': uniform(0.1, 0.3), 'init_value': 0.1},\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "automl.fit(X_train=train_set.features, y_train=train_set.target, **automl_settings)\n",
    "print('Best hyperparameters:', automl.best_config)\n",
    "\n",
    "best_params = automl.best_config\n",
    "best_model = xgb.train(best_params, train_d_matrix, num_boost_round=100)\n",
    "\n",
    "val_predictions = best_model.predict(val_d_matrix)\n",
    "mae = mean_absolute_error(val_set.target, val_predictions)\n",
    "print(f'Validation MAE: {mae}')\n",
    "\n",
    "test_predictions = best_model.predict(test_d_matrix)\n",
    "mse = mean_absolute_error(test_set.target, test_predictions)\n",
    "print(f'Test MAE: {mae}')"
   ],
   "id": "ea1da5d0387b3037",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 06-12 19:36:58] {1680} INFO - task = regression\n",
      "[flaml.automl.logger: 06-12 19:36:58] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 06-12 19:36:58] {1789} INFO - Minimizing error metric: mae\n",
      "[flaml.automl.logger: 06-12 19:36:58] {1901} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
      "[flaml.automl.logger: 06-12 19:36:58] {2219} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:36:58] {2345} INFO - Estimated sufficient time budget=4629s. Estimated necessary time budget=5s.\n",
      "[flaml.automl.logger: 06-12 19:36:58] {2392} INFO -  at 0.5s,\testimator xgboost's best error=11951.3111,\tbest estimator xgboost's best error=11951.3111\n",
      "[flaml.automl.logger: 06-12 19:36:58] {2219} INFO - iteration 1, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:36:59] {2392} INFO -  at 0.9s,\testimator xgboost's best error=11951.3111,\tbest estimator xgboost's best error=11951.3111\n",
      "[flaml.automl.logger: 06-12 19:36:59] {2219} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:36:59] {2392} INFO -  at 1.3s,\testimator xgboost's best error=11951.3111,\tbest estimator xgboost's best error=11951.3111\n",
      "[flaml.automl.logger: 06-12 19:36:59] {2219} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:00] {2392} INFO -  at 1.8s,\testimator xgboost's best error=11293.3110,\tbest estimator xgboost's best error=11293.3110\n",
      "[flaml.automl.logger: 06-12 19:37:00] {2219} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:00] {2392} INFO -  at 2.3s,\testimator xgboost's best error=11293.3110,\tbest estimator xgboost's best error=11293.3110\n",
      "[flaml.automl.logger: 06-12 19:37:00] {2219} INFO - iteration 5, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:01] {2392} INFO -  at 3.0s,\testimator xgboost's best error=11046.4507,\tbest estimator xgboost's best error=11046.4507\n",
      "[flaml.automl.logger: 06-12 19:37:01] {2219} INFO - iteration 6, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:01] {2392} INFO -  at 3.5s,\testimator xgboost's best error=11046.4507,\tbest estimator xgboost's best error=11046.4507\n",
      "[flaml.automl.logger: 06-12 19:37:01] {2219} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:02] {2392} INFO -  at 4.0s,\testimator xgboost's best error=11046.4507,\tbest estimator xgboost's best error=11046.4507\n",
      "[flaml.automl.logger: 06-12 19:37:02] {2219} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:03] {2392} INFO -  at 5.3s,\testimator xgboost's best error=10945.8642,\tbest estimator xgboost's best error=10945.8642\n",
      "[flaml.automl.logger: 06-12 19:37:03] {2219} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:04] {2392} INFO -  at 6.2s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:04] {2219} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:05] {2392} INFO -  at 7.4s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:05] {2219} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:08] {2392} INFO -  at 10.5s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:08] {2219} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:09] {2392} INFO -  at 10.9s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:09] {2219} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:10] {2392} INFO -  at 11.8s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:10] {2219} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:11] {2392} INFO -  at 13.0s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:11] {2219} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:11] {2392} INFO -  at 13.4s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:11] {2219} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:14] {2392} INFO -  at 16.4s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:14] {2219} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:15] {2392} INFO -  at 17.5s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:15] {2219} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:16] {2392} INFO -  at 18.5s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:16] {2219} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:17] {2392} INFO -  at 19.2s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:17] {2219} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:18] {2392} INFO -  at 20.6s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:18] {2219} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:19] {2392} INFO -  at 21.5s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:19] {2219} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:20] {2392} INFO -  at 22.6s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:20] {2219} INFO - iteration 23, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:23] {2392} INFO -  at 25.0s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:23] {2219} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:23] {2392} INFO -  at 25.5s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:23] {2219} INFO - iteration 25, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:25] {2392} INFO -  at 27.4s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:25] {2219} INFO - iteration 26, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:26] {2392} INFO -  at 28.0s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:26] {2219} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:26] {2392} INFO -  at 28.6s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:26] {2219} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:28] {2392} INFO -  at 30.3s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:28] {2219} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:29] {2392} INFO -  at 30.8s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:29] {2219} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:32] {2392} INFO -  at 34.0s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:32] {2219} INFO - iteration 31, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:34] {2392} INFO -  at 35.7s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:34] {2219} INFO - iteration 32, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:34] {2392} INFO -  at 36.3s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:34] {2219} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:35] {2392} INFO -  at 37.3s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:35] {2219} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:37] {2392} INFO -  at 39.5s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:37] {2219} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:38] {2392} INFO -  at 40.1s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:38] {2219} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:40] {2392} INFO -  at 41.7s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:40] {2219} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:40] {2392} INFO -  at 42.2s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:40] {2219} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:43] {2392} INFO -  at 45.0s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:43] {2219} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:45] {2392} INFO -  at 46.9s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:45] {2219} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:45] {2392} INFO -  at 47.4s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:45] {2219} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:46] {2392} INFO -  at 47.9s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:46] {2219} INFO - iteration 42, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:48] {2392} INFO -  at 50.3s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:48] {2219} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:49] {2392} INFO -  at 51.0s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:49] {2219} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:50] {2392} INFO -  at 52.3s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:50] {2219} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:51] {2392} INFO -  at 53.5s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:51] {2219} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:52] {2392} INFO -  at 54.5s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:52] {2219} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:53] {2392} INFO -  at 55.3s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:53] {2219} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:54] {2392} INFO -  at 56.6s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:54] {2219} INFO - iteration 49, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:56] {2392} INFO -  at 58.1s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:56] {2219} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:57] {2392} INFO -  at 58.8s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:57] {2219} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl.logger: 06-12 19:37:58] {2392} INFO -  at 60.0s,\testimator xgboost's best error=10586.7094,\tbest estimator xgboost's best error=10586.7094\n",
      "[flaml.automl.logger: 06-12 19:37:58] {2526} INFO - [('xgboost', {'n_jobs': 4, 'n_estimators': 11, 'max_leaves': 12, 'min_child_weight': 51.37030455618672, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.6848592747070127, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.026004986983265897, 'max_depth': 6, 'learning_rate': 0.22429508632862516, 'subsample': 0.6558972772416146, 'verbosity': 0})]\n",
      "[flaml.automl.logger: 06-12 19:37:58] {2628} INFO - retrain xgboost for 0.2s\n",
      "[flaml.automl.logger: 06-12 19:37:58] {2631} INFO - retrained model: XGBRegressor(base_score=None, booster=None, callbacks=[], colsample_bylevel=1.0,\n",
      "             colsample_bynode=None, colsample_bytree=0.6848592747070127,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.22429508632862516, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=6, max_leaves=12,\n",
      "             min_child_weight=51.37030455618672, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=11,\n",
      "             n_jobs=4, num_parallel_tree=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 06-12 19:37:58] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 06-12 19:37:58] {1932} INFO - Time taken to find the best model: 6.1743738651275635\n",
      "Best hyperparameters: {'n_estimators': 11, 'max_leaves': 12, 'min_child_weight': 51.37030455618672, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.6848592747070127, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.026004986983265897, 'max_depth': 6, 'learning_rate': 0.22429508632862516, 'subsample': 0.6558972772416146}\n",
      "Validation MAE: 10745.897920891206\n",
      "Test MAE: 10745.897920891206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colin\\PycharmProjects\\claim_cost\\claim_cost_env\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [19:37:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T18:37:58.598467Z",
     "start_time": "2024-06-12T18:37:58.595501Z"
    }
   },
   "cell_type": "code",
   "source": "train_set.target.mean()",
   "id": "9390e8e4e57a4cb6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9858.126561618863"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T18:37:58.602136Z",
     "start_time": "2024-06-12T18:37:58.599468Z"
    }
   },
   "cell_type": "code",
   "source": "mean_array = np.full(len(val_set.target), train_set.target.mean())",
   "id": "91a30ae839ec1a71",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T18:37:58.606816Z",
     "start_time": "2024-06-12T18:37:58.602136Z"
    }
   },
   "cell_type": "code",
   "source": "mean_absolute_error(val_set.target, mean_array)",
   "id": "85560135b48c28de",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10361.366256205712"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T18:37:58.608669Z",
     "start_time": "2024-06-12T18:37:58.606816Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3720cc56fff77a0e",
   "outputs": [],
   "execution_count": 56
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
