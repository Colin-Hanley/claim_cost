{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-10T20:18:18.404995Z",
     "start_time": "2024-06-10T20:18:16.835218Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "claims_data = pd.read_excel(\"claims_data.xlsx\")"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:18:18.409502Z",
     "start_time": "2024-06-10T20:18:18.404995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "claims_data.loc[claims_data[\"Notification_period\"] < 0, \"Notification_period\"] = np.nan\n",
    "claims_data.loc[claims_data[\"PH_considered_TP_at_fault\"] == \"#\", \"PH_considered_TP_at_fault\"] = np.nan"
   ],
   "id": "2eb1972bed8b5e2e",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:18:18.414260Z",
     "start_time": "2024-06-10T20:18:18.409502Z"
    }
   },
   "cell_type": "code",
   "source": "claims_data.drop(columns=[\"Claim Number\", \"date_of_loss\", \"Loss_code\", \"Loss_description\", \"Capped Incurred\"], inplace=True)",
   "id": "d6d63a91b7f56b28",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:18:18.420894Z",
     "start_time": "2024-06-10T20:18:18.415262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#change the columns with object datatype to category\n",
    "for col in claims_data.select_dtypes(include=[\"object\"]).columns:\n",
    "    claims_data[col] = claims_data[col].astype(\"category\")\n",
    "   "
   ],
   "id": "6e7b7699f9b7ab40",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:18:18.435352Z",
     "start_time": "2024-06-10T20:18:18.420894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot_encode_categorical_columns(df: pd.DataFrame) -> (pd.DataFrame, OneHotEncoder):\n",
    "    \"\"\"\n",
    "    One-hot encodes all categorical columns in the DataFrame using OneHotEncoder.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing columns to be encoded.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with categorical columns one-hot encoded.\n",
    "    \"\"\"\n",
    "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "    encoded_df = pd.DataFrame(ohe.fit_transform(df[categorical_columns]))\n",
    "    \n",
    "    # Name the columns appropriately\n",
    "    encoded_df.columns = ohe.get_feature_names_out(categorical_columns)\n",
    "    df = df.drop(columns=categorical_columns).reset_index(drop=True)\n",
    "    encoded_df = encoded_df.reset_index(drop=True)\n",
    "    \n",
    "    return pd.concat([df, encoded_df], axis=1), ohe\n",
    "\n",
    "encoded_claims, encoder = one_hot_encode_categorical_columns(claims_data)"
   ],
   "id": "ace2bf4967f4c7c3",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:18:18.438845Z",
     "start_time": "2024-06-10T20:18:18.435352Z"
    }
   },
   "cell_type": "code",
   "source": "encoder.get_feature_names_out()",
   "id": "4f73618cdd3a43fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Notifier_NamedDriver', 'Notifier_Other', 'Notifier_PH',\n",
       "       'Notifier_TP', 'Location_of_incident_Home Address',\n",
       "       'Location_of_incident_Main Road',\n",
       "       'Location_of_incident_Minor Road', 'Location_of_incident_Motorway',\n",
       "       'Location_of_incident_Not Applicable',\n",
       "       'Location_of_incident_Other', 'Location_of_incident_n/k',\n",
       "       'Weather_conditions_NORMAL', 'Weather_conditions_SNOW,ICE,FOG',\n",
       "       'Weather_conditions_WET', 'Weather_conditions_nan',\n",
       "       'Vehicle_mobile_Y', 'Vehicle_mobile_n/k', 'Main_driver_Other',\n",
       "       'Main_driver_Y', 'PH_considered_TP_at_fault_Y',\n",
       "       'PH_considered_TP_at_fault_n/k', 'PH_considered_TP_at_fault_nan'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:18:18.451882Z",
     "start_time": "2024-06-10T20:18:18.439357Z"
    }
   },
   "cell_type": "code",
   "source": "encoded_claims",
   "id": "37ca161dd09092eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Notification_period  Inception_to_loss  Time_hour  \\\n",
       "0                    22.0                 13         10   \n",
       "1                     1.0                  9         18   \n",
       "2                     5.0                 17         16   \n",
       "3                     1.0                 23         14   \n",
       "4                     1.0                 48          9   \n",
       "...                   ...                ...        ...   \n",
       "7686                  1.0                 83         16   \n",
       "7687                  0.0                 25         14   \n",
       "7688                  0.0                 60          9   \n",
       "7689                  1.0                253         19   \n",
       "7690                  0.0                266         14   \n",
       "\n",
       "      Vechile_registration_present  Incident_details_present  \\\n",
       "0                                1                         0   \n",
       "1                                1                         1   \n",
       "2                                1                         0   \n",
       "3                                1                         1   \n",
       "4                                1                         1   \n",
       "...                            ...                       ...   \n",
       "7686                             1                         1   \n",
       "7687                             1                         1   \n",
       "7688                             1                         1   \n",
       "7689                             1                         1   \n",
       "7690                             1                         1   \n",
       "\n",
       "      Injury_details_present  TP_type_insd_pass_back  TP_type_insd_pass_front  \\\n",
       "0                          0                       0                        0   \n",
       "1                          0                       0                        0   \n",
       "2                          0                       0                        0   \n",
       "3                          0                       0                        0   \n",
       "4                          0                       0                        0   \n",
       "...                      ...                     ...                      ...   \n",
       "7686                       1                       0                        0   \n",
       "7687                       1                       0                        0   \n",
       "7688                       0                       0                        0   \n",
       "7689                       1                       0                        0   \n",
       "7690                       0                       0                        0   \n",
       "\n",
       "      TP_type_driver  TP_type_pass_back  ...  Weather_conditions_SNOW,ICE,FOG  \\\n",
       "0                  0                  0  ...                              0.0   \n",
       "1                  0                  0  ...                              0.0   \n",
       "2                  0                  0  ...                              0.0   \n",
       "3                  0                  0  ...                              0.0   \n",
       "4                  0                  0  ...                              0.0   \n",
       "...              ...                ...  ...                              ...   \n",
       "7686               1                  0  ...                              0.0   \n",
       "7687               1                  0  ...                              0.0   \n",
       "7688               1                  0  ...                              0.0   \n",
       "7689               1                  0  ...                              0.0   \n",
       "7690               1                  0  ...                              0.0   \n",
       "\n",
       "      Weather_conditions_WET  Weather_conditions_nan  Vehicle_mobile_Y  \\\n",
       "0                        0.0                     0.0               1.0   \n",
       "1                        1.0                     0.0               1.0   \n",
       "2                        1.0                     0.0               1.0   \n",
       "3                        0.0                     0.0               1.0   \n",
       "4                        0.0                     0.0               0.0   \n",
       "...                      ...                     ...               ...   \n",
       "7686                     0.0                     0.0               0.0   \n",
       "7687                     0.0                     1.0               1.0   \n",
       "7688                     0.0                     0.0               1.0   \n",
       "7689                     0.0                     0.0               0.0   \n",
       "7690                     0.0                     0.0               1.0   \n",
       "\n",
       "      Vehicle_mobile_n/k  Main_driver_Other  Main_driver_Y  \\\n",
       "0                    0.0                1.0            0.0   \n",
       "1                    0.0                1.0            0.0   \n",
       "2                    0.0                0.0            1.0   \n",
       "3                    0.0                1.0            0.0   \n",
       "4                    0.0                1.0            0.0   \n",
       "...                  ...                ...            ...   \n",
       "7686                 0.0                1.0            0.0   \n",
       "7687                 0.0                0.0            1.0   \n",
       "7688                 0.0                1.0            0.0   \n",
       "7689                 0.0                1.0            0.0   \n",
       "7690                 0.0                0.0            1.0   \n",
       "\n",
       "      PH_considered_TP_at_fault_Y  PH_considered_TP_at_fault_n/k  \\\n",
       "0                             0.0                            1.0   \n",
       "1                             0.0                            1.0   \n",
       "2                             0.0                            1.0   \n",
       "3                             0.0                            1.0   \n",
       "4                             0.0                            1.0   \n",
       "...                           ...                            ...   \n",
       "7686                          0.0                            0.0   \n",
       "7687                          0.0                            0.0   \n",
       "7688                          0.0                            0.0   \n",
       "7689                          0.0                            0.0   \n",
       "7690                          0.0                            0.0   \n",
       "\n",
       "      PH_considered_TP_at_fault_nan  \n",
       "0                               0.0  \n",
       "1                               0.0  \n",
       "2                               0.0  \n",
       "3                               0.0  \n",
       "4                               0.0  \n",
       "...                             ...  \n",
       "7686                            0.0  \n",
       "7687                            0.0  \n",
       "7688                            0.0  \n",
       "7689                            0.0  \n",
       "7690                            0.0  \n",
       "\n",
       "[7691 rows x 57 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Notification_period</th>\n",
       "      <th>Inception_to_loss</th>\n",
       "      <th>Time_hour</th>\n",
       "      <th>Vechile_registration_present</th>\n",
       "      <th>Incident_details_present</th>\n",
       "      <th>Injury_details_present</th>\n",
       "      <th>TP_type_insd_pass_back</th>\n",
       "      <th>TP_type_insd_pass_front</th>\n",
       "      <th>TP_type_driver</th>\n",
       "      <th>TP_type_pass_back</th>\n",
       "      <th>...</th>\n",
       "      <th>Weather_conditions_SNOW,ICE,FOG</th>\n",
       "      <th>Weather_conditions_WET</th>\n",
       "      <th>Weather_conditions_nan</th>\n",
       "      <th>Vehicle_mobile_Y</th>\n",
       "      <th>Vehicle_mobile_n/k</th>\n",
       "      <th>Main_driver_Other</th>\n",
       "      <th>Main_driver_Y</th>\n",
       "      <th>PH_considered_TP_at_fault_Y</th>\n",
       "      <th>PH_considered_TP_at_fault_n/k</th>\n",
       "      <th>PH_considered_TP_at_fault_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7686</th>\n",
       "      <td>1.0</td>\n",
       "      <td>83</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7687</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7688</th>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7689</th>\n",
       "      <td>1.0</td>\n",
       "      <td>253</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7690</th>\n",
       "      <td>0.0</td>\n",
       "      <td>266</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7691 rows Ã— 57 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:18:18.454506Z",
     "start_time": "2024-06-10T20:18:18.451882Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split",
   "id": "9e4698759cf41735",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:18:18.456362Z",
     "start_time": "2024-06-10T20:18:18.454506Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7315c09e92fbbc56",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:18:18.464613Z",
     "start_time": "2024-06-10T20:18:18.457369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train, temp = train_test_split(claims_data, test_size=0.25, random_state=32, shuffle=True)\n",
    "val, test = train_test_split(temp, test_size=0.4, random_state=32, shuffle=True)\n",
    "\n",
    "# Display the results\n",
    "print(\"Training data size:\", len(train) / (len(train) + len(val) + len(test)) )\n",
    "print(\"Validation data size:\", len(val) / (len(train) + len(val) + len(test)))\n",
    "print(\"Testing data size:\", len(test)/ (len(train) + len(val) + len(test)))"
   ],
   "id": "67783be8bea27b03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 0.7499674944740606\n",
      "Validation data size: 0.14991548563255752\n",
      "Testing data size: 0.10011701989338187\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:18:18.485179Z",
     "start_time": "2024-06-10T20:18:18.464613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import namedtuple\n",
    "DataSet = namedtuple('DataSet', ['features', 'target'])\n",
    "train_set = DataSet(features=train.drop(columns=\"Incurred\"), target=train[\"Incurred\"])\n",
    "val_set = DataSet(features=val.drop(columns=\"Incurred\"), target=val[\"Incurred\"])\n",
    "test_set = DataSet(features=test.drop(columns =\"Incurred\") , target=test[\"Incurred\"])\n",
    "train_d_matrix = xgb.DMatrix(train_set.features, label=train_set.target, enable_categorical=True)\n",
    "val_d_matrix = xgb.DMatrix(val_set.features, label=val_set.target, enable_categorical=True)\n",
    "test_d_matrix = xgb.DMatrix(test_set.features, label=test_set.target, enable_categorical=True)"
   ],
   "id": "688a19c0a71f83e6",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T20:21:42.821698Z",
     "start_time": "2024-06-10T20:20:38.049016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from flaml import AutoML\n",
    "\n",
    "automl = AutoML()\n",
    "\n",
    "automl_settings = {\n",
    "    \"time_budget\": 60,  # total running time in seconds\n",
    "    \"metric\": 'mae',  # metric to optimize\n",
    "    \"task\": 'regression',  # task type\n",
    "    \"n_splits\": 5,  # number of splits in time cross-validation\n",
    "    \"sample\": True,  # enable sampling\n",
    "    \"estimator_list\": ['xgboost',\"xgb_limitdepth\",\"histgb\"],  # list of ML algorithms to use\n",
    "    \"log_file_name\": 'flaml.log',  # log file\n",
    "    \"eval_method\": \"cv\",  # cross-validation\n",
    "    \"max_iter\": 200,  # maximum number of iterations\n",
    "    \"early_stop\": True,  # enable early stopping\n",
    "    \"n_jobs\": 4,  # number of parallel jobs\n",
    "    \"ensemble\": True,  # use ensemble methods\n",
    "}\n",
    "\n",
    "automl.fit(X_train=train_set.features, y_train=train_set.target, **automl_settings)\n",
    "print('Best hyperparameters:', automl.best_config)\n",
    "\n",
    "best_params = automl.best_config\n",
    "best_model = xgb.train(best_params, train_d_matrix, num_boost_round=100)\n",
    "\n",
    "val_predictions = best_model.predict(val_d_matrix)\n",
    "mae = mean_absolute_error(val_set.target, val_predictions)\n",
    "print(f'Validation MAE: {mae}')\n",
    "\n",
    "test_predictions = best_model.predict(test_d_matrix)\n",
    "mse = mean_absolute_error(test_set.target, test_predictions)\n",
    "print(f'Test MAE: {mae}')"
   ],
   "id": "ea1da5d0387b3037",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 06-10 21:20:38] {1680} INFO - task = regression\n",
      "[flaml.automl.logger: 06-10 21:20:38] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 06-10 21:20:38] {1789} INFO - Minimizing error metric: mae\n",
      "[flaml.automl.logger: 06-10 21:20:38] {1901} INFO - List of ML learners in AutoML Run: ['xgboost', 'xgb_limitdepth', 'histgb']\n",
      "[flaml.automl.logger: 06-10 21:20:38] {2219} INFO - iteration 0, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:38] {2345} INFO - Estimated sufficient time budget=5199s. Estimated necessary time budget=22s.\n",
      "[flaml.automl.logger: 06-10 21:20:38] {2392} INFO -  at 0.6s,\testimator xgboost's best error=12516.3445,\tbest estimator xgboost's best error=12516.3445\n",
      "[flaml.automl.logger: 06-10 21:20:38] {2219} INFO - iteration 1, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:38] {2392} INFO -  at 0.6s,\testimator histgb's best error=12152.4122,\tbest estimator histgb's best error=12152.4122\n",
      "[flaml.automl.logger: 06-10 21:20:38] {2219} INFO - iteration 2, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:38] {2392} INFO -  at 0.7s,\testimator histgb's best error=12152.4122,\tbest estimator histgb's best error=12152.4122\n",
      "[flaml.automl.logger: 06-10 21:20:38] {2219} INFO - iteration 3, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:38] {2392} INFO -  at 0.8s,\testimator histgb's best error=11316.3755,\tbest estimator histgb's best error=11316.3755\n",
      "[flaml.automl.logger: 06-10 21:20:38] {2219} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:39] {2392} INFO -  at 1.2s,\testimator xgboost's best error=12516.3445,\tbest estimator histgb's best error=11316.3755\n",
      "[flaml.automl.logger: 06-10 21:20:39] {2219} INFO - iteration 5, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:39] {2392} INFO -  at 1.3s,\testimator histgb's best error=10937.4554,\tbest estimator histgb's best error=10937.4554\n",
      "[flaml.automl.logger: 06-10 21:20:39] {2219} INFO - iteration 6, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:39] {2392} INFO -  at 1.3s,\testimator histgb's best error=10914.3025,\tbest estimator histgb's best error=10914.3025\n",
      "[flaml.automl.logger: 06-10 21:20:39] {2219} INFO - iteration 7, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:39] {2392} INFO -  at 1.7s,\testimator xgboost's best error=12516.3445,\tbest estimator histgb's best error=10914.3025\n",
      "[flaml.automl.logger: 06-10 21:20:39] {2219} INFO - iteration 8, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:39] {2392} INFO -  at 1.8s,\testimator histgb's best error=10410.9052,\tbest estimator histgb's best error=10410.9052\n",
      "[flaml.automl.logger: 06-10 21:20:39] {2219} INFO - iteration 9, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:39] {2392} INFO -  at 1.9s,\testimator histgb's best error=10410.9052,\tbest estimator histgb's best error=10410.9052\n",
      "[flaml.automl.logger: 06-10 21:20:39] {2219} INFO - iteration 10, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2392} INFO -  at 2.0s,\testimator histgb's best error=10410.9052,\tbest estimator histgb's best error=10410.9052\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2219} INFO - iteration 11, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2392} INFO -  at 2.1s,\testimator histgb's best error=10410.9052,\tbest estimator histgb's best error=10410.9052\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2219} INFO - iteration 12, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2392} INFO -  at 2.2s,\testimator histgb's best error=10265.9940,\tbest estimator histgb's best error=10265.9940\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2219} INFO - iteration 13, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2392} INFO -  at 2.3s,\testimator histgb's best error=9875.9839,\tbest estimator histgb's best error=9875.9839\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2219} INFO - iteration 14, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2392} INFO -  at 2.4s,\testimator histgb's best error=9468.8070,\tbest estimator histgb's best error=9468.8070\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2219} INFO - iteration 15, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2392} INFO -  at 2.5s,\testimator histgb's best error=9468.8070,\tbest estimator histgb's best error=9468.8070\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2219} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2392} INFO -  at 2.8s,\testimator xgboost's best error=11585.7909,\tbest estimator histgb's best error=9468.8070\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2219} INFO - iteration 17, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2392} INFO -  at 2.9s,\testimator histgb's best error=9362.5618,\tbest estimator histgb's best error=9362.5618\n",
      "[flaml.automl.logger: 06-10 21:20:40] {2219} INFO - iteration 18, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:41] {2392} INFO -  at 3.0s,\testimator histgb's best error=9362.5618,\tbest estimator histgb's best error=9362.5618\n",
      "[flaml.automl.logger: 06-10 21:20:41] {2219} INFO - iteration 19, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:41] {2392} INFO -  at 3.1s,\testimator histgb's best error=9362.5618,\tbest estimator histgb's best error=9362.5618\n",
      "[flaml.automl.logger: 06-10 21:20:41] {2219} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:41] {2392} INFO -  at 3.4s,\testimator xgboost's best error=11585.7909,\tbest estimator histgb's best error=9362.5618\n",
      "[flaml.automl.logger: 06-10 21:20:41] {2219} INFO - iteration 21, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:41] {2392} INFO -  at 3.5s,\testimator histgb's best error=9362.5618,\tbest estimator histgb's best error=9362.5618\n",
      "[flaml.automl.logger: 06-10 21:20:41] {2219} INFO - iteration 22, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:41] {2392} INFO -  at 3.7s,\testimator histgb's best error=9362.5618,\tbest estimator histgb's best error=9362.5618\n",
      "[flaml.automl.logger: 06-10 21:20:41] {2219} INFO - iteration 23, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:42] {2392} INFO -  at 4.0s,\testimator histgb's best error=9323.9654,\tbest estimator histgb's best error=9323.9654\n",
      "[flaml.automl.logger: 06-10 21:20:42] {2219} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:42] {2392} INFO -  at 4.3s,\testimator xgboost's best error=11585.7909,\tbest estimator histgb's best error=9323.9654\n",
      "[flaml.automl.logger: 06-10 21:20:42] {2219} INFO - iteration 25, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:42] {2392} INFO -  at 4.4s,\testimator histgb's best error=9323.9654,\tbest estimator histgb's best error=9323.9654\n",
      "[flaml.automl.logger: 06-10 21:20:42] {2219} INFO - iteration 26, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:42] {2392} INFO -  at 4.6s,\testimator histgb's best error=9323.9654,\tbest estimator histgb's best error=9323.9654\n",
      "[flaml.automl.logger: 06-10 21:20:42] {2219} INFO - iteration 27, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:43] {2392} INFO -  at 5.1s,\testimator histgb's best error=9323.9654,\tbest estimator histgb's best error=9323.9654\n",
      "[flaml.automl.logger: 06-10 21:20:43] {2219} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:43] {2392} INFO -  at 5.8s,\testimator xgboost's best error=11310.9669,\tbest estimator histgb's best error=9323.9654\n",
      "[flaml.automl.logger: 06-10 21:20:43] {2219} INFO - iteration 29, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:44] {2392} INFO -  at 6.6s,\testimator xgboost's best error=11310.9669,\tbest estimator histgb's best error=9323.9654\n",
      "[flaml.automl.logger: 06-10 21:20:44] {2219} INFO - iteration 30, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:44] {2392} INFO -  at 6.9s,\testimator xgboost's best error=11277.4707,\tbest estimator histgb's best error=9323.9654\n",
      "[flaml.automl.logger: 06-10 21:20:44] {2219} INFO - iteration 31, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:45] {2392} INFO -  at 7.1s,\testimator histgb's best error=9323.9654,\tbest estimator histgb's best error=9323.9654\n",
      "[flaml.automl.logger: 06-10 21:20:45] {2219} INFO - iteration 32, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:45] {2392} INFO -  at 7.4s,\testimator xgboost's best error=10885.3512,\tbest estimator histgb's best error=9323.9654\n",
      "[flaml.automl.logger: 06-10 21:20:45] {2219} INFO - iteration 33, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:45] {2392} INFO -  at 7.7s,\testimator xgboost's best error=10885.3512,\tbest estimator histgb's best error=9323.9654\n",
      "[flaml.automl.logger: 06-10 21:20:45] {2219} INFO - iteration 34, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:46] {2392} INFO -  at 8.2s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:46] {2219} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:46] {2392} INFO -  at 8.6s,\testimator xgboost's best error=10885.3512,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:46] {2219} INFO - iteration 36, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:47] {2392} INFO -  at 9.2s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:47] {2219} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:47] {2392} INFO -  at 9.8s,\testimator xgboost's best error=10492.7639,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:47] {2219} INFO - iteration 38, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:48] {2392} INFO -  at 10.4s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:48] {2219} INFO - iteration 39, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:50] {2392} INFO -  at 12.1s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:50] {2219} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:50] {2392} INFO -  at 12.4s,\testimator xgboost's best error=10492.7639,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:50] {2219} INFO - iteration 41, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:50] {2392} INFO -  at 12.6s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:50] {2219} INFO - iteration 42, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:50] {2392} INFO -  at 12.9s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:50] {2219} INFO - iteration 43, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:51] {2392} INFO -  at 13.4s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:51] {2219} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:52] {2392} INFO -  at 14.4s,\testimator xgboost's best error=10492.7639,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:52] {2219} INFO - iteration 45, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:52] {2392} INFO -  at 14.9s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:52] {2219} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:53] {2392} INFO -  at 15.6s,\testimator xgboost's best error=10492.7639,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:53] {2219} INFO - iteration 47, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:54] {2392} INFO -  at 16.3s,\testimator xgboost's best error=10492.7639,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:54] {2219} INFO - iteration 48, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:54] {2392} INFO -  at 16.6s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:54] {2219} INFO - iteration 49, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:55] {2392} INFO -  at 17.0s,\testimator xgboost's best error=10492.7639,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:55] {2219} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:56] {2392} INFO -  at 18.2s,\testimator xgboost's best error=10492.7639,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:56] {2219} INFO - iteration 51, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:56] {2392} INFO -  at 18.7s,\testimator xgboost's best error=10492.7639,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:56] {2219} INFO - iteration 52, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:57] {2392} INFO -  at 19.6s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:57] {2219} INFO - iteration 53, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:20:57] {2392} INFO -  at 19.8s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:57] {2219} INFO - iteration 54, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:58] {2392} INFO -  at 20.8s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:58] {2219} INFO - iteration 55, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:20:59] {2392} INFO -  at 21.8s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:20:59] {2219} INFO - iteration 56, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:00] {2392} INFO -  at 22.5s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:00] {2219} INFO - iteration 57, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:01] {2392} INFO -  at 23.0s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:01] {2219} INFO - iteration 58, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:01] {2392} INFO -  at 23.1s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:01] {2219} INFO - iteration 59, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:02] {2392} INFO -  at 24.7s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:02] {2219} INFO - iteration 60, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:04] {2392} INFO -  at 26.0s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:04] {2219} INFO - iteration 61, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:04] {2392} INFO -  at 26.2s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:04] {2219} INFO - iteration 62, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:04] {2392} INFO -  at 26.6s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:04] {2219} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:06] {2392} INFO -  at 28.6s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:06] {2219} INFO - iteration 64, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:07] {2392} INFO -  at 29.0s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:07] {2219} INFO - iteration 65, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:07] {2392} INFO -  at 29.8s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:07] {2219} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:08] {2392} INFO -  at 30.9s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:08] {2219} INFO - iteration 67, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:09] {2392} INFO -  at 31.4s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:09] {2219} INFO - iteration 68, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:10] {2392} INFO -  at 32.0s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:10] {2219} INFO - iteration 69, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:10] {2392} INFO -  at 32.2s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:10] {2219} INFO - iteration 70, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:11] {2392} INFO -  at 33.8s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:11] {2219} INFO - iteration 71, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:12] {2392} INFO -  at 34.0s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:12] {2219} INFO - iteration 72, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:12] {2392} INFO -  at 34.6s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:12] {2219} INFO - iteration 73, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:13] {2392} INFO -  at 35.0s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:13] {2219} INFO - iteration 74, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:15] {2392} INFO -  at 37.7s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:15] {2219} INFO - iteration 75, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:16] {2392} INFO -  at 38.2s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:16] {2219} INFO - iteration 76, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:16] {2392} INFO -  at 38.9s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:16] {2219} INFO - iteration 77, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:18] {2392} INFO -  at 40.2s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:18] {2219} INFO - iteration 78, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:18] {2392} INFO -  at 40.7s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:18] {2219} INFO - iteration 79, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:20] {2392} INFO -  at 42.2s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:20] {2219} INFO - iteration 80, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:21] {2392} INFO -  at 43.0s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:21] {2219} INFO - iteration 81, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:21] {2392} INFO -  at 43.3s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:21] {2219} INFO - iteration 82, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:21] {2392} INFO -  at 43.6s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:21] {2219} INFO - iteration 83, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:22] {2392} INFO -  at 44.3s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:22] {2219} INFO - iteration 84, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:23] {2392} INFO -  at 45.1s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:23] {2219} INFO - iteration 85, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:23] {2392} INFO -  at 45.8s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:23] {2219} INFO - iteration 86, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:27] {2392} INFO -  at 49.6s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:27] {2219} INFO - iteration 87, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:27] {2392} INFO -  at 49.9s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:27] {2219} INFO - iteration 88, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:28] {2392} INFO -  at 50.2s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:28] {2219} INFO - iteration 89, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:28] {2392} INFO -  at 50.8s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:28] {2219} INFO - iteration 90, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:29] {2392} INFO -  at 51.1s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:29] {2219} INFO - iteration 91, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:30] {2392} INFO -  at 52.7s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:30] {2219} INFO - iteration 92, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:31] {2392} INFO -  at 53.8s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:31] {2219} INFO - iteration 93, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:32] {2392} INFO -  at 54.0s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:32] {2219} INFO - iteration 94, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:33] {2392} INFO -  at 55.3s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:33] {2219} INFO - iteration 95, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:33] {2392} INFO -  at 55.5s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:33] {2219} INFO - iteration 96, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:34] {2392} INFO -  at 56.8s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:34] {2219} INFO - iteration 97, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:35] {2392} INFO -  at 57.4s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:35] {2219} INFO - iteration 98, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:36] {2392} INFO -  at 58.8s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:36] {2219} INFO - iteration 99, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:37] {2392} INFO -  at 59.0s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:37] {2219} INFO - iteration 100, current learner xgboost\n",
      "[flaml.automl.logger: 06-10 21:21:37] {2392} INFO -  at 59.5s,\testimator xgboost's best error=10432.6623,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:37] {2219} INFO - iteration 101, current learner histgb\n",
      "[flaml.automl.logger: 06-10 21:21:38] {2392} INFO -  at 60.0s,\testimator histgb's best error=9288.0257,\tbest estimator histgb's best error=9288.0257\n",
      "[flaml.automl.logger: 06-10 21:21:38] {2526} INFO - [('histgb', {'min_samples_leaf': 10, 'learning_rate': 0.06469362209242696, 'l2_regularization': 168.07251152366229, 'max_iter': 51, 'max_bins': 31, 'max_leaf_nodes': 56, 'random_state': 24092023, 'verbose': 0}), ('xgboost', {'n_jobs': 4, 'n_estimators': 17, 'max_leaves': 78, 'min_child_weight': 55.92741817283653, 'learning_rate': 0.12904177960301766, 'subsample': 0.9517459550978583, 'colsample_bylevel': 0.8833142421826156, 'colsample_bytree': 0.7905070827922056, 'reg_alpha': 0.006187866394146251, 'reg_lambda': 0.8018707904571978, 'max_depth': 0, 'grow_policy': 'lossguide', 'tree_method': 'hist', 'verbosity': 0})]\n",
      "[flaml.automl.logger: 06-10 21:21:38] {2569} INFO - Building ensemble with tuned estimators\n",
      "[flaml.automl.logger: 06-10 21:21:39] {2580} WARNING - Using passthrough=False for ensemble because the data contain categorical features.\n",
      "[flaml.automl.logger: 06-10 21:21:42] {2594} INFO - ensemble: StackingRegressor(estimators=[('histgb',\n",
      "                               <flaml.automl.contrib.histgb.HistGradientBoostingEstimator object at 0x000001F4826DB470>),\n",
      "                              ('xgboost',\n",
      "                               <flaml.automl.model.XGBoostSklearnEstimator object at 0x000001F4826D87D0>)],\n",
      "                  n_jobs=4)\n",
      "[flaml.automl.logger: 06-10 21:21:42] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 06-10 21:21:42] {1932} INFO - Time taken to find the best model: 8.152006149291992\n",
      "Best hyperparameters: {'n_estimators': 51, 'max_leaves': 56, 'min_samples_leaf': 10, 'learning_rate': 0.06469362209242696, 'log_max_bin': 5, 'l2_regularization': 168.07251152366229, 'max_iter': 51}\n",
      "Validation MAE: 6726.954621723219\n",
      "Test MAE: 6726.954621723219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colin\\PycharmProjects\\claim_cost\\claim_cost_env\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [21:21:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"l2_regularization\", \"log_max_bin\", \"max_iter\", \"min_samples_leaf\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_set.target.mean()",
   "id": "9390e8e4e57a4cb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(val_set.features)",
   "id": "c392c5806c74baf0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "val_set.features[\"Avg_prediction\"] = train_set.target.mean()",
   "id": "34da53cb2552b348",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "val_set.features",
   "id": "beb21e9bbde37335",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mean_absolute_error(val_set.target, val_set.features[\"Avg_prediction\"])\n",
    "\n",
    "# I beleive the MAE of the trained model last night was 6ksh so this is a material improvement"
   ],
   "id": "5b7466c0b5ee1231",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
